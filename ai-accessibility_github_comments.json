[
    {
        "id": 2472731320,
        "issue_url": "https://api.github.com/repos/w3c/ai-accessibility/issues/2",
        "created_at": "2024-11-13T07:55:31Z",
        "updated_at": "2024-11-13T07:55:31Z",
        "body": "The way this has been structured is based on user feedback. In terms of the innovation roadmap, the ultimate request from users is that accessibility issues are resolved by AI seamlessly without user intervention. Some AI innovations like autogenerated alt text for example, if accurate, would address this so user agent accessibility done on-the-fly would be a possible innovation roadmap, but widely applicable across other technologies as AI develops.\r\n\r\nMost of the document focuses on AI potential and accessibility issues, but acknowledges it is still fairly general in most use cases. However, some recent developments are becoming improved such as recent integration of Google Gemini into Talkback on Android. It is much better than Microsoft AI examples mentioned here for alt text. Also, there are notable improvements with live captioning. Hence, I think we can look at things AI could do well but are still in their infancy. Sign language for example, isn't really effective yet despite apps being available and is also very localised by mostly ASL. This could be an example of something that is really good that does not exist without AI, but if AI improves, then sign language online could become effective over time.\r\n\r\nIt is true that there is a lot of focus on automation, but I think there is a differentiation between how users can benefit from AI seamlessly and how people trying to address accessibility issues can also be supported by AI.",
        "user": "sehollier",
        "is_owner": false,
        "is_contributor": false,
        "repository_id": "w3c/ai-accessibility"
    },
    {
        "id": 2472733215,
        "issue_url": "https://api.github.com/repos/w3c/ai-accessibility/issues/3",
        "created_at": "2024-11-13T07:56:44Z",
        "updated_at": "2024-11-13T07:56:44Z",
        "body": "Agreed.",
        "user": "sehollier",
        "is_owner": false,
        "is_contributor": false,
        "repository_id": "w3c/ai-accessibility"
    },
    {
        "id": 2472734197,
        "issue_url": "https://api.github.com/repos/w3c/ai-accessibility/issues/4",
        "created_at": "2024-11-13T07:57:22Z",
        "updated_at": "2024-11-13T07:57:22Z",
        "body": "Agreed.",
        "user": "sehollier",
        "is_owner": false,
        "is_contributor": false,
        "repository_id": "w3c/ai-accessibility"
    },
    {
        "id": 2472741727,
        "issue_url": "https://api.github.com/repos/w3c/ai-accessibility/issues/5",
        "created_at": "2024-11-13T08:01:35Z",
        "updated_at": "2024-11-13T08:01:35Z",
        "body": "I think GIGO is a really good point. One of the challenges with AI is that is lies with confidence and therefore it is hard to determine. For example, autogenerated alt text will change every time it is created, even if it is the exact same image. Which one is correct? Perhaps all of them, perhaps one of them. Each time subtle details are changed yet all versions may still be helpful. So how to consider these issues would be good to add in.\r\n\r\nAnother example is live captioning, if 9 out of 10 words are accurate and paired with curated content, is this enough for an end-user to have reliable information or is the inaccuracies which are represented without warning too much of a problem for the end-user.",
        "user": "sehollier",
        "is_owner": false,
        "is_contributor": false,
        "repository_id": "w3c/ai-accessibility"
    },
    {
        "id": 2472745955,
        "issue_url": "https://api.github.com/repos/w3c/ai-accessibility/issues/6",
        "created_at": "2024-11-13T08:03:25Z",
        "updated_at": "2024-11-13T08:03:25Z",
        "body": "Agreed as it relates to comments in Issue #2.",
        "user": "sehollier",
        "is_owner": false,
        "is_contributor": false,
        "repository_id": "w3c/ai-accessibility"
    },
    {
        "id": 2472767527,
        "issue_url": "https://api.github.com/repos/w3c/ai-accessibility/issues/7",
        "created_at": "2024-11-13T08:09:06Z",
        "updated_at": "2024-11-13T08:09:06Z",
        "body": "Agreed, this should be fleshed out. For example, the recent Talkback update on Android provides user choice on whether alt text that is already present is used or generative AI alt text is used, and also provides the opportunity for multiple attempts on AI alt text results. However, it never indicates the accuracy of these alt texts unlike in Microsoft 365, where Microsoft does acknowledge its view on confidence levels, i.e. low confidence, high confidence of its alt text. That being said, sometimes its high confidence is still very wrong, so this all needs to be explained in this guidance.\r\n\r\nAgree with the suggested approach but would still like to differentiate between the user experience of AI and professionals tasked with using AI to address accessibility issues.",
        "user": "sehollier",
        "is_owner": false,
        "is_contributor": false,
        "repository_id": "w3c/ai-accessibility"
    },
    {
        "id": 2472834701,
        "issue_url": "https://api.github.com/repos/w3c/ai-accessibility/issues/2",
        "created_at": "2024-11-13T08:34:39Z",
        "updated_at": "2024-11-13T08:34:39Z",
        "body": "Another example of a user benefit not necessarily about repair might be connected to some of our XR guidance, where tactile representation in XR space could be generated to support people who are blind. AI could scan images to determine the texture of objects, represent them in a 3D environment, and then provide haptic feedback to the user.",
        "user": "sehollier",
        "is_owner": false,
        "is_contributor": false,
        "repository_id": "w3c/ai-accessibility"
    }
]